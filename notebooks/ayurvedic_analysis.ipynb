{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7e6e6d4",
   "metadata": {},
   "source": [
    "# Ayurvedic Medicine Sensor Analysis Pipeline\n",
    "\n",
    "This notebook demonstrates the complete machine learning pipeline for analyzing NIR sensor data from Ayurvedic medicines. We'll cover:\n",
    "\n",
    "1. Data loading and validation\n",
    "2. Exploratory data analysis\n",
    "3. Feature engineering\n",
    "4. Model development and training\n",
    "5. Evaluation and visualization\n",
    "6. Production deployment\n",
    "\n",
    "## Setup Requirements\n",
    "- Python 3.8+\n",
    "- Required packages: pandas, numpy, scikit-learn, tensorflow, plotly, fastapi\n",
    "- Git repository for version control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d34cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data.preprocessing import DataPreprocessor\n",
    "from src.features.engineering import FeatureEngineer\n",
    "from src.models.ensemble import EnsembleModel\n",
    "from src.visualization.plots import Visualizer\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedf92a1",
   "metadata": {},
   "source": [
    "# Data Loading and Validation\n",
    "\n",
    "Let's create a sample dataset and demonstrate the data loading and validation pipeline. Our dataset should have the following structure:\n",
    "- 6 NIR wavelength sensors (R,S,T,U,V,W)\n",
    "- Temperature readings\n",
    "- Dilution percentages (100%, 75%, 50%, 25%, 10%)\n",
    "- Medicine names (3-4 different medicines)\n",
    "- Effectiveness scores\n",
    "- Reading IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e6c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define parameters\n",
    "n_samples_per_dilution = 25\n",
    "dilution_levels = [100, 75, 50, 25, 10]\n",
    "medicines = ['Ashwagandha', 'Turmeric', 'Tulsi', 'Neem']\n",
    "n_total_samples = n_samples_per_dilution * len(dilution_levels) * len(medicines)\n",
    "\n",
    "# Generate synthetic data\n",
    "data = []\n",
    "reading_id = 1\n",
    "\n",
    "for medicine in medicines:\n",
    "    for dilution in dilution_levels:\n",
    "        for _ in range(n_samples_per_dilution):\n",
    "            # Base sensor readings (higher for higher dilutions)\n",
    "            base_readings = np.random.normal(dilution/20, 2, 6)\n",
    "            \n",
    "            # Add medicine-specific patterns\n",
    "            if medicine == 'Ashwagandha':\n",
    "                base_readings[0] *= 1.2  # Stronger R response\n",
    "            elif medicine == 'Turmeric':\n",
    "                base_readings[2] *= 1.3  # Stronger T response\n",
    "            elif medicine == 'Tulsi':\n",
    "                base_readings[4] *= 1.4  # Stronger V response\n",
    "            else:  # Neem\n",
    "                base_readings[5] *= 1.5  # Stronger W response\n",
    "            \n",
    "            # Temperature variation\n",
    "            temperature = np.random.normal(25, 2)\n",
    "            \n",
    "            # Effectiveness score (correlated with dilution and some noise)\n",
    "            effectiveness = (dilution/100) * np.random.normal(1, 0.1)\n",
    "            \n",
    "            # Ensure non-negative values\n",
    "            base_readings = np.maximum(base_readings, 0)\n",
    "            \n",
    "            data.append({\n",
    "                'R': base_readings[0],\n",
    "                'S': base_readings[1],\n",
    "                'T': base_readings[2],\n",
    "                'U': base_readings[3],\n",
    "                'V': base_readings[4],\n",
    "                'W': base_readings[5],\n",
    "                'Temperature': temperature,\n",
    "                'Dilution_Percent': dilution,\n",
    "                'Medicine_Name': medicine,\n",
    "                'Effectiveness_Score': effectiveness,\n",
    "                'Reading_ID': reading_id\n",
    "            })\n",
    "            reading_id += 1\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "df.to_csv('../data/sensor_readings.csv', index=False)\n",
    "print(\"Sample data generated and saved to '../data/sensor_readings.csv'\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff92e82d",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Feature Engineering\n",
    "\n",
    "Now let's preprocess the data and create engineered features using our custom modules. We'll:\n",
    "1. Initialize the data preprocessor\n",
    "2. Load and validate the data\n",
    "3. Apply temperature compensation\n",
    "4. Normalize features\n",
    "5. Engineer additional features using wavelength ratios and spectral derivatives\n",
    "6. Apply PCA for dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9403de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize processors\n",
    "preprocessor = DataPreprocessor()\n",
    "feature_engineer = FeatureEngineer()\n",
    "\n",
    "# Load and preprocess data\n",
    "df = preprocessor.load_data('../data/sensor_readings.csv')\n",
    "df_comp = preprocessor.temperature_compensation(df)\n",
    "df_norm = preprocessor.normalize_features(df_comp)\n",
    "\n",
    "# Prepare feature matrix\n",
    "X = np.hstack([\n",
    "    df_norm[preprocessor.sensor_columns].values,\n",
    "    df_norm[[preprocessor.temp_column]].values\n",
    "])\n",
    "\n",
    "# Engineer features\n",
    "features = feature_engineer.engineer_features(\n",
    "    df_norm[preprocessor.sensor_columns].values,\n",
    "    df_norm[preprocessor.temp_column].values\n",
    ")\n",
    "\n",
    "print(\"Original features shape:\", X.shape)\n",
    "print(\"Engineered features shape:\", features['combined'].shape)\n",
    "print(\"PCA features shape:\", features['pca'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e9c7af",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "\n",
    "Let's create visualizations to understand our data better:\n",
    "1. Sensor reading distributions\n",
    "2. Temperature vs sensor response\n",
    "3. Dilution level effects\n",
    "4. Medicine type patterns\n",
    "5. Feature correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb4727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualizer\n",
    "visualizer = Visualizer()\n",
    "\n",
    "# Plot sensor readings over time\n",
    "fig_readings = visualizer.plot_sensor_readings(df)\n",
    "fig_readings.show()\n",
    "\n",
    "# Plot dilution curves\n",
    "fig_dilution = visualizer.plot_dilution_curves(df)\n",
    "fig_dilution.show()\n",
    "\n",
    "# Create correlation heatmap\n",
    "corr_matrix = df[preprocessor.sensor_columns + [preprocessor.temp_column, 'Dilution_Percent', 'Effectiveness_Score']].corr()\n",
    "fig_corr = go.Figure(data=go.Heatmap(\n",
    "    z=corr_matrix,\n",
    "    x=corr_matrix.columns,\n",
    "    y=corr_matrix.columns,\n",
    "    colorscale='RdBu'\n",
    "))\n",
    "fig_corr.update_layout(\n",
    "    title='Feature Correlations',\n",
    "    width=800,\n",
    "    height=800\n",
    ")\n",
    "fig_corr.show()\n",
    "\n",
    "# Plot PCA components\n",
    "pca_df = pd.DataFrame(\n",
    "    features['pca'],\n",
    "    columns=[f'PC{i+1}' for i in range(features['pca'].shape[1])]\n",
    ")\n",
    "pca_df['Medicine'] = df['Medicine_Name']\n",
    "pca_df['Dilution'] = df['Dilution_Percent']\n",
    "\n",
    "fig_pca = px.scatter_3d(\n",
    "    pca_df,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    z='PC3',\n",
    "    color='Medicine',\n",
    "    size='Dilution',\n",
    "    title='PCA Components by Medicine Type and Dilution'\n",
    ")\n",
    "fig_pca.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9595e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "train_data, test_data = preprocessor.prepare_data(df)\n",
    "\n",
    "# Initialize and train model\n",
    "model = EnsembleModel()\n",
    "cv_scores = model.train(\n",
    "    train_data['X'],\n",
    "    train_data['y_dilution'],\n",
    "    train_data['y_medicine'],\n",
    "    train_data['y_effectiveness']\n",
    ")\n",
    "\n",
    "# Generate predictions for test data\n",
    "test_predictions = model.predict(test_data['X'])\n",
    "\n",
    "# Create true values dictionary for visualization\n",
    "true_values = {\n",
    "    'dilution': test_data['y_dilution'],\n",
    "    'medicine': test_data['y_medicine'],\n",
    "    'effectiveness': test_data['y_effectiveness']\n",
    "}\n",
    "\n",
    "# Plot model performance\n",
    "fig_performance = visualizer.plot_model_performance(cv_scores)\n",
    "fig_performance.show()\n",
    "\n",
    "# Plot prediction confidence\n",
    "fig_confidence = visualizer.plot_prediction_confidence(\n",
    "    test_predictions,\n",
    "    true_values\n",
    ")\n",
    "fig_confidence.show()\n",
    "\n",
    "# Calculate and display metrics\n",
    "for target in ['dilution', 'medicine', 'effectiveness']:\n",
    "    print(f\"\\n{target.capitalize()} Predictions:\")\n",
    "    print(f\"Mean prediction: {np.mean(test_predictions[target]['predictions']):.2f}\")\n",
    "    print(f\"Mean confidence: {np.mean(test_predictions[target]['confidence']):.2f}\")\n",
    "\n",
    "# Save the trained model\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "model.save_models('../models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0c28af",
   "metadata": {},
   "source": [
    "# Real-time Prediction Example\n",
    "\n",
    "Finally, let's demonstrate how to use the API for real-time predictions:\n",
    "1. Create a sample sensor reading\n",
    "2. Send it to the prediction endpoint\n",
    "3. Visualize the results with confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample reading\n",
    "sample_reading = {\n",
    "    'R': 3.5,\n",
    "    'S': 2.8,\n",
    "    'T': 4.2,\n",
    "    'U': 3.0,\n",
    "    'V': 3.8,\n",
    "    'W': 2.5,\n",
    "    'Temperature': 25.0\n",
    "}\n",
    "\n",
    "# Convert to numpy array\n",
    "sample_X = np.array([[\n",
    "    sample_reading['R'],\n",
    "    sample_reading['S'],\n",
    "    sample_reading['T'],\n",
    "    sample_reading['U'],\n",
    "    sample_reading['V'],\n",
    "    sample_reading['W'],\n",
    "    sample_reading['Temperature']\n",
    "]])\n",
    "\n",
    "# Preprocess the sample\n",
    "sample_X_norm = preprocessor.normalize_features(\n",
    "    preprocessor.temperature_compensation(pd.DataFrame([sample_reading]))\n",
    ").values\n",
    "\n",
    "# Engineer features\n",
    "sample_features = feature_engineer.engineer_features(\n",
    "    sample_X_norm[:, :-1],\n",
    "    sample_X_norm[:, -1],\n",
    "    fit=False\n",
    ")\n",
    "\n",
    "# Generate predictions\n",
    "sample_predictions = model.predict(sample_features['combined'])\n",
    "\n",
    "# Display results\n",
    "print(\"Prediction Results:\")\n",
    "print(f\"Dilution: {sample_predictions['dilution']['predictions'][0]:.1f}% (confidence: {sample_predictions['dilution']['confidence'][0]:.2f})\")\n",
    "print(f\"Medicine: {sample_predictions['medicine']['predictions'][0]} (confidence: {sample_predictions['medicine']['confidence'][0]:.2f})\")\n",
    "print(f\"Effectiveness: {sample_predictions['effectiveness']['predictions'][0]:.2f} (confidence: {sample_predictions['effectiveness']['confidence'][0]:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
